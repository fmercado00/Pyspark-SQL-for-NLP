{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using window function SQL for Natural Language.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "gJSdGydxEcFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98cSMasU3jyi",
        "outputId": "985c6a48-47b4-43d5-f3c3-e072ff67999b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Pyspark"
      ],
      "metadata": {
        "id": "ceQStDeAEaLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOxdoec64LYE",
        "outputId": "6f3776fe-9af5-4047-e58d-53bdc4a64564"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 42 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 37.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=ac0265eb259fdbc75987955a1b6312504074675f1c505ec3edebdc9c84d9012b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Spark session"
      ],
      "metadata": {
        "id": "uyCVetS1Eus1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "t33a_7r74Q_y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Text file"
      ],
      "metadata": {
        "id": "hmLxSbe3IJjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/drive/My Drive/sherlock.txt'\n",
        "df = spark.read.text(filename)\n",
        "print(df.first())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXLma_jY4YIB",
        "outputId": "5b1c4d26-aa31-40f6-e60f-15e0d7b7a250"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(value='The Project Gutenberg EBook of The Adventures of Sherlock Holmes')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJqVj2s1KMxS",
        "outputId": "46685feb-777e-4506-8d51-dead6291f30f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Parquet file"
      ],
      "metadata": {
        "id": "528iuagJKZeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/drive/My Drive/sherlock.parquet'\n",
        "df1 = spark.read.load(filename)"
      ],
      "metadata": {
        "id": "2qcK7Y_iKaAA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading first 10 rows"
      ],
      "metadata": {
        "id": "3cXq3tr6MWUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzChAoe_KqtB",
        "outputId": "74c9b843-d027-40fa-9800-d5dbe42090ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|word      |id |\n",
            "+----------+---+\n",
            "|the       |0  |\n",
            "|project   |1  |\n",
            "|gutenberg |2  |\n",
            "|ebook     |3  |\n",
            "|of        |4  |\n",
            "|the       |5  |\n",
            "|adventures|6  |\n",
            "|of        |7  |\n",
            "|sherlock  |8  |\n",
            "|holmes    |9  |\n",
            "+----------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter and show the first 5 rows"
      ],
      "metadata": {
        "id": "4iTvW_2nJEKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.where('id > 70').show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laFZ3kYqJRPZ",
        "outputId": "07fd456e-c87c-4aa9-8dd9-60bdce1509d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|word  |id |\n",
            "+------+---+\n",
            "|it    |71 |\n",
            "|do    |72 |\n",
            "|not   |73 |\n",
            "|change|74 |\n",
            "|or    |75 |\n",
            "+------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show 15 rows without truncate"
      ],
      "metadata": {
        "id": "A1tkkAYxPPic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(15, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fMRu7Ho9DoB",
        "outputId": "14a422c1-6aff-470c-9fb1-63f66068143b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "|value                                                               |\n",
            "+--------------------------------------------------------------------+\n",
            "|The Project Gutenberg EBook of The Adventures of Sherlock Holmes    |\n",
            "|by Sir Arthur Conan Doyle                                           |\n",
            "|(#15 in our series by Sir Arthur Conan Doyle)                       |\n",
            "|                                                                    |\n",
            "|Copyright laws are changing all over the world. Be sure to check the|\n",
            "|copyright laws for your country before downloading or redistributing|\n",
            "|this or any other Project Gutenberg eBook.                          |\n",
            "|                                                                    |\n",
            "|This header should be the first thing seen when viewing this Project|\n",
            "|Gutenberg file.  Please do not remove it.  Do not change or edit the|\n",
            "|header without written permission.                                  |\n",
            "|                                                                    |\n",
            "|Please read the \"legal small print,\" and other information about the|\n",
            "|eBook and Project Gutenberg at the bottom of this file.  Included is|\n",
            "|important information about your specific rights and restrictions in|\n",
            "+--------------------------------------------------------------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show columns"
      ],
      "metadata": {
        "id": "8tXNz9FsQYD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH8r2XcSQcgv",
        "outputId": "523afbf2-8553-446a-e89f-203f9b27b90d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['value']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower case operation"
      ],
      "metadata": {
        "id": "h0Dp7wIXPiga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower\n",
        "df_lower = df.select(lower(col('value')))\n",
        "print(df_lower.first())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aihvw8SePoCt",
        "outputId": "4532a557-eb0a-4fdc-8ed2-07928500d58c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(lower(value)='the project gutenberg ebook of the adventures of sherlock holmes')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lower.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKzB-MXf93XK",
        "outputId": "c7aa8d56-c6c8-4785-f91f-ca39778f4aff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lower(value)']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alias operation"
      ],
      "metadata": {
        "id": "eO9JDed6-L47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_lower = df.select(lower(col('value')).alias('v'))\n",
        "df_lower.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rwac6Yq-QmV",
        "outputId": "0ab6bcb7-1a20-4cd2-c4df-16bba60bb95b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['v']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replacing text\n",
        "Mr.Holmes.==> Mr Holmes."
      ],
      "metadata": {
        "id": "VUQqTieO-7NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "df_replaced = df.select(regexp_replace('value', 'Mr\\.', 'Mr').alias('v'))\n"
      ],
      "metadata": {
        "id": "nWyeuzZX-6bg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "don't know.==>do not know.\n"
      ],
      "metadata": {
        "id": "SrvfL9nRTOIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_replaced = df_replaced.select(regexp_replace('v', 'don\\'t', 'do not').alias('v'))"
      ],
      "metadata": {
        "id": "lqUlXL24TO-i"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing text"
      ],
      "metadata": {
        "id": "GKwryrI4DbGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split\n",
        "df_replaced1 = df_replaced.select(split('v', '[ ]').alias('words'))\n",
        "df_replaced1.show(truncate=False)"
      ],
      "metadata": {
        "id": "T0iDmyT9DboL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ea26d1-60ca-4169-e193-1f17e43528e8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------+\n",
            "|words                                                                                 |\n",
            "+--------------------------------------------------------------------------------------+\n",
            "|[The, Project, Gutenberg, EBook, of, The, Adventures, of, Sherlock, Holmes]           |\n",
            "|[by, Sir, Arthur, Conan, Doyle]                                                       |\n",
            "|[(#15, in, our, series, by, Sir, Arthur, Conan, Doyle)]                               |\n",
            "|[]                                                                                    |\n",
            "|[Copyright, laws, are, changing, all, over, the, world., Be, sure, to, check, the]    |\n",
            "|[copyright, laws, for, your, country, before, downloading, or, redistributing]        |\n",
            "|[this, or, any, other, Project, Gutenberg, eBook.]                                    |\n",
            "|[]                                                                                    |\n",
            "|[This, header, should, be, the, first, thing, seen, when, viewing, this, Project]     |\n",
            "|[Gutenberg, file., , Please, do, not, remove, it., , Do, not, change, or, edit, the]  |\n",
            "|[header, without, written, permission.]                                               |\n",
            "|[]                                                                                    |\n",
            "|[Please, read, the, \"legal, small, print,\", and, other, information, about, the]      |\n",
            "|[eBook, and, Project, Gutenberg, at, the, bottom, of, this, file., , Included, is]    |\n",
            "|[important, information, about, your, specific, rights, and, restrictions, in]        |\n",
            "|[how, the, file, may, be, used., , You, can, also, find, out, about, how, to, make, a]|\n",
            "|[donation, to, Project, Gutenberg,, and, how, to, get, involved.]                     |\n",
            "|[]                                                                                    |\n",
            "|[]                                                                                    |\n",
            "|[**Welcome, To, The, World, of, Free, Plain, Vanilla, Electronic, Texts**]            |\n",
            "+--------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split characters are discarded"
      ],
      "metadata": {
        "id": "IY0mGwzoMCzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = \"_|.\\?\\!\\\",\\'\\[\\]\\*()\"\n",
        "df_replaced2 = df_replaced.select(split('v','[ %s]' % punctuation).alias('words'))\n",
        "df_replaced2.show(truncate=False)"
      ],
      "metadata": {
        "id": "NvX620S1MHrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f249ddf8-5a2e-47a4-913c-4fd62d9f01de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------+\n",
            "|words                                                                                  |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "|[The, Project, Gutenberg, EBook, of, The, Adventures, of, Sherlock, Holmes]            |\n",
            "|[by, Sir, Arthur, Conan, Doyle]                                                        |\n",
            "|[, #15, in, our, series, by, Sir, Arthur, Conan, Doyle, ]                              |\n",
            "|[]                                                                                     |\n",
            "|[Copyright, laws, are, changing, all, over, the, world, , Be, sure, to, check, the]    |\n",
            "|[copyright, laws, for, your, country, before, downloading, or, redistributing]         |\n",
            "|[this, or, any, other, Project, Gutenberg, eBook, ]                                    |\n",
            "|[]                                                                                     |\n",
            "|[This, header, should, be, the, first, thing, seen, when, viewing, this, Project]      |\n",
            "|[Gutenberg, file, , , Please, do, not, remove, it, , , Do, not, change, or, edit, the] |\n",
            "|[header, without, written, permission, ]                                               |\n",
            "|[]                                                                                     |\n",
            "|[Please, read, the, , legal, small, print, , , and, other, information, about, the]    |\n",
            "|[eBook, and, Project, Gutenberg, at, the, bottom, of, this, file, , , Included, is]    |\n",
            "|[important, information, about, your, specific, rights, and, restrictions, in]         |\n",
            "|[how, the, file, may, be, used, , , You, can, also, find, out, about, how, to, make, a]|\n",
            "|[donation, to, Project, Gutenberg, , and, how, to, get, involved, ]                    |\n",
            "|[]                                                                                     |\n",
            "|[]                                                                                     |\n",
            "|[, , Welcome, To, The, World, of, Free, Plain, Vanilla, Electronic, Texts, , ]         |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploding an array"
      ],
      "metadata": {
        "id": "QkYOZqKjO6c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df_replaced3 = df_replaced2.select(explode('words').alias('word'))\n",
        "df_replaced3.show()"
      ],
      "metadata": {
        "id": "QOh0gCSIOxfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c81673-bd49-4cf1-dd6f-fcf1a8626e36"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|      word|\n",
            "+----------+\n",
            "|       The|\n",
            "|   Project|\n",
            "| Gutenberg|\n",
            "|     EBook|\n",
            "|        of|\n",
            "|       The|\n",
            "|Adventures|\n",
            "|        of|\n",
            "|  Sherlock|\n",
            "|    Holmes|\n",
            "|        by|\n",
            "|       Sir|\n",
            "|    Arthur|\n",
            "|     Conan|\n",
            "|     Doyle|\n",
            "|          |\n",
            "|       #15|\n",
            "|        in|\n",
            "|       our|\n",
            "|    series|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "daHw2NebZuIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_replaced2.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxlzE7VTZuzz",
        "outputId": "ec68d439-26c4-4f6c-90bf-115729310c86"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explode increases rowcount\n"
      ],
      "metadata": {
        "id": "0ndAPrlqZB66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_replaced3.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y56Uj_MZQ7i",
        "outputId": "75cc7426-8923-417a-ade6-ff6d0ff0a008"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1356337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing empty rows"
      ],
      "metadata": {
        "id": "oufkdteEPXVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "print(df_replaced3.count())\n",
        "nonblank_df = df_replaced3.where(length('word') > 0)\n",
        "print(nonblank_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ4OnZkZPbED",
        "outputId": "bdea44a6-96fd-4fae-ec73-dbe8a707d1d9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1356337\n",
            "1106521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding a row id column"
      ],
      "metadata": {
        "id": "vxfgRTIcRdc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "df2 = nonblank_df.select('word', monotonically_increasing_id().alias('id'))\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "Y1s8VzYjQEsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb56154-e39f-4e11-f05d-3b8cce28d640"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|      word| id|\n",
            "+----------+---+\n",
            "|       The|  0|\n",
            "|   Project|  1|\n",
            "| Gutenberg|  2|\n",
            "|     EBook|  3|\n",
            "|        of|  4|\n",
            "|       The|  5|\n",
            "|Adventures|  6|\n",
            "|        of|  7|\n",
            "|  Sherlock|  8|\n",
            "|    Holmes|  9|\n",
            "|        by| 10|\n",
            "|       Sir| 11|\n",
            "|    Arthur| 12|\n",
            "|     Conan| 13|\n",
            "|     Doyle| 14|\n",
            "|       #15| 15|\n",
            "|        in| 16|\n",
            "|       our| 17|\n",
            "|    series| 18|\n",
            "|        by| 19|\n",
            "+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partition the data"
      ],
      "metadata": {
        "id": "0hPdGMFITvSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df3 = df2.withColumn('title', when(df2.id < 25000, 'Preface')\n",
        "                                              .when(df2.id < 50000, 'Chapter 1')\n",
        "                                              .when(df2.id < 75000, 'Chapter 2')\n",
        "                                              .otherwise('Chapter 3')\n",
        ")\n",
        "\n",
        "df4 = df3.withColumn('part', when(df3.id < 25000, 0)\n",
        "                                              .when(df3.id < 50000, 1)\n",
        "                                              .when(df3.id < 75000, 2)\n",
        "                                              .otherwise(3))\n",
        "df4.show()"
      ],
      "metadata": {
        "id": "glNU4y4WTzCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abad4b7b-80c7-4ab2-bdea-732a83328b41"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+-------+----+\n",
            "|      word| id|  title|part|\n",
            "+----------+---+-------+----+\n",
            "|       The|  0|Preface|   0|\n",
            "|   Project|  1|Preface|   0|\n",
            "| Gutenberg|  2|Preface|   0|\n",
            "|     EBook|  3|Preface|   0|\n",
            "|        of|  4|Preface|   0|\n",
            "|       The|  5|Preface|   0|\n",
            "|Adventures|  6|Preface|   0|\n",
            "|        of|  7|Preface|   0|\n",
            "|  Sherlock|  8|Preface|   0|\n",
            "|    Holmes|  9|Preface|   0|\n",
            "|        by| 10|Preface|   0|\n",
            "|       Sir| 11|Preface|   0|\n",
            "|    Arthur| 12|Preface|   0|\n",
            "|     Conan| 13|Preface|   0|\n",
            "|     Doyle| 14|Preface|   0|\n",
            "|       #15| 15|Preface|   0|\n",
            "|        in| 16|Preface|   0|\n",
            "|       our| 17|Preface|   0|\n",
            "|    series| 18|Preface|   0|\n",
            "|        by| 19|Preface|   0|\n",
            "+----------+---+-------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Repartitioning on a column"
      ],
      "metadata": {
        "id": "QZKOqzM7bCtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df4.repartition(4, 'part')\n",
        "print(df5.rdd.getNumPartitions())"
      ],
      "metadata": {
        "id": "XvfAf3AmbBtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6506e1ff-e646-400c-eff3-485c9302fba6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios"
      ],
      "metadata": {
        "id": "SIQXJYbUeBpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating context window feature data"
      ],
      "metadata": {
        "id": "lWbV4tAaRN62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5.createOrReplaceTempView(\"text\")"
      ],
      "metadata": {
        "id": "NDxeQ73QROZV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word for each row, previous two and subsequent two words"
      ],
      "metadata": {
        "id": "bQrkWvcutUBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "part,\n",
        "LAG(word, 2) OVER(PARTITION BY part ORDER BY id) AS w1,\n",
        "LAG(word, 1) OVER(PARTITION BY part ORDER BY id) AS w2,\n",
        "word AS w3,\n",
        "LEAD(word, 1) OVER(PARTITION BY part ORDER BY id) AS w4,\n",
        "LEAD(word, 2) OVER(PARTITION BY part ORDER BY id) AS w5\n",
        "FROM text\n",
        "\"\"\"\n",
        "spark.sql(query).where(\"part = 2\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adsiHlUas38R",
        "outputId": "48bf2195-39b1-462f-abe8-9b5a2ac18864"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+-------+-------+-------+-------+\n",
            "|part|     w1|     w2|     w3|     w4|     w5|\n",
            "+----+-------+-------+-------+-------+-------+\n",
            "|   2|   null|   null|    You|  would|   have|\n",
            "|   2|   null|    You|  would|   have|   done|\n",
            "|   2|    You|  would|   have|   done| better|\n",
            "|   2|  would|   have|   done| better|     to|\n",
            "|   2|   have|   done| better|     to|   have|\n",
            "|   2|   done| better|     to|   have|trusted|\n",
            "|   2| better|     to|   have|trusted|    you|\n",
            "|   2|     to|   have|trusted|    you|   wife|\n",
            "|   2|   have|trusted|    you|   wife|     It|\n",
            "|   2|trusted|    you|   wife|     It|    was|\n",
            "+----+-------+-------+-------+-------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df5.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkpR8aN8tnli",
        "outputId": "884b49a4-2ebd-4c03-d0b1-ce2b554b9dd8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+---------+----+\n",
            "|    word|   id|    title|part|\n",
            "+--------+-----+---------+----+\n",
            "|     You|50000|Chapter 2|   2|\n",
            "|   would|50001|Chapter 2|   2|\n",
            "|    have|50002|Chapter 2|   2|\n",
            "|    done|50003|Chapter 2|   2|\n",
            "|  better|50004|Chapter 2|   2|\n",
            "|      to|50005|Chapter 2|   2|\n",
            "|    have|50006|Chapter 2|   2|\n",
            "| trusted|50007|Chapter 2|   2|\n",
            "|     you|50008|Chapter 2|   2|\n",
            "|    wife|50009|Chapter 2|   2|\n",
            "|      It|50010|Chapter 2|   2|\n",
            "|     was|50011|Chapter 2|   2|\n",
            "|     not|50012|Chapter 2|   2|\n",
            "|     the|50013|Chapter 2|   2|\n",
            "|   wife;|50014|Chapter 2|   2|\n",
            "|      it|50015|Chapter 2|   2|\n",
            "|     was|50016|Chapter 2|   2|\n",
            "|     the|50017|Chapter 2|   2|\n",
            "|children|50018|Chapter 2|   2|\n",
            "| groaned|50019|Chapter 2|   2|\n",
            "+--------+-----+---------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding common word sequences"
      ],
      "metadata": {
        "id": "nW47rRmwu2iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the top 10 sequences of five words"
      ],
      "metadata": {
        "id": "rcXw25HZvVZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT w1, w2, w3, w4, w5, COUNT(*) AS count FROM (\n",
        "   SELECT word AS w1,\n",
        "   LEAD(word,1) OVER(PARTITION BY part ORDER BY id) AS w2,\n",
        "   LEAD(word,2) OVER(PARTITION BY part ORDER BY id) AS w3,\n",
        "   LEAD(word,3) OVER(PARTITION BY part ORDER BY id) AS w4,\n",
        "   LEAD(word,4) OVER(PARTITION BY part ORDER BY id) AS w5\n",
        "   FROM text\n",
        ")\n",
        "GROUP BY w1, w2, w3, w4, w5\n",
        "ORDER BY count DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "df = spark.sql(query)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oe4UvUIvV3k",
        "outputId": "ae378e23-2444-459a-9dbb-90dd7a2a2570"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+--------+-------+----------+-----+\n",
            "|     w1|       w2|      w3|     w4|        w5|count|\n",
            "+-------+---------+--------+-------+----------+-----+\n",
            "|History|       of|     the| United|    States|   57|\n",
            "|     in|      the|  region|     of|       the|   36|\n",
            "|Project|Gutenberg|Literary|Archive|Foundation|   35|\n",
            "|     of|      the|  United| States|        pp|   31|\n",
            "|     in|      the|  middle|     of|       the|   27|\n",
            "|    the|    other|    side|     of|       the|   25|\n",
            "|     on|      the|    same|  lines|        as|   25|\n",
            "|     in|      the|    case|     of|       the|   25|\n",
            "|     up|      and|    down|    the|      room|   23|\n",
            "|    and|       at|     the|   same|      time|   23|\n",
            "+-------+---------+--------+-------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unique 5-tuples sorted in descending order"
      ],
      "metadata": {
        "id": "rSedrxqev1zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT DISTINCT w1, w2, w3, w4, w5 FROM (\n",
        "   SELECT word AS w1,\n",
        "   LEAD(word,1) OVER(PARTITION BY part ORDER BY id ) AS w2,\n",
        "   LEAD(word,2) OVER(PARTITION BY part ORDER BY id ) AS w3,\n",
        "   LEAD(word,3) OVER(PARTITION BY part ORDER BY id ) AS w4,\n",
        "   LEAD(word,4) OVER(PARTITION BY part ORDER BY id ) AS w5\n",
        "   FROM text\n",
        ")\n",
        "ORDER BY w1 DESC, w2 DESC, w3 DESC, w4 DESC, w5 DESC \n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "df = spark.sql(query)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50dI8Dr4v30S",
        "outputId": "95d2a205-b7ae-435a-c417-8f936a49c568"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-------+----------+------------+\n",
            "|       w1|       w2|     w3|        w4|          w5|\n",
            "+---------+---------+-------+----------+------------+\n",
            "|        ~| asterisk|    and| underline|  characters|\n",
            "|zygomatic|      and|frontal|     bones|         the|\n",
            "|   zygoma|       in|  front|        of|         the|\n",
            "|       zu|     sein|   Vera|        at|         the|\n",
            "|       zu|schwachen|     so|      kann|         man|\n",
            "|  zoology|      was|    not|    merely|acknowledged|\n",
            "|  zoology|      for|     in|         a|        frog|\n",
            "|  zoology|      and|     so|        on|        just|\n",
            "|zone--not|      the|    red|margin--an|  artificial|\n",
            "|     zone|    which|   lies|     about|        half|\n",
            "+---------+---------+-------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###   Most frequent 3-tuple per chapter  "
      ],
      "metadata": {
        "id": "4upofWYuwhlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subquery = \"\"\"\n",
        "SELECT title, w1, w2, w3, COUNT(*) as count\n",
        "FROM\n",
        "(\n",
        "    SELECT\n",
        "    title,\n",
        "    word AS w1,\n",
        "    LEAD(word, 1) OVER(PARTITION BY title ORDER BY id ) AS w2,\n",
        "    LEAD(word, 2) OVER(PARTITION BY title ORDER BY id ) AS w3\n",
        "    FROM text\n",
        ")\n",
        "GROUP BY title, w1, w2, w3\n",
        "ORDER BY title, count DESC\n",
        "\"\"\"\n",
        "spark.sql(subquery).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2ncu2aDxgKB",
        "outputId": "e40af575-c6a4-4f2f-a914-52f897349200"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+---+-----+-----+\n",
            "|    title|     w1| w2|   w3|count|\n",
            "+---------+-------+---+-----+-----+\n",
            "|Chapter 1|   that| he|  was|   16|\n",
            "|Chapter 1|Neville| St|Clair|   14|\n",
            "|Chapter 1|      I| do|  not|   13|\n",
            "|Chapter 1|   that| he|  had|   11|\n",
            "|Chapter 1|    one| of|  the|   10|\n",
            "+---------+-------+---+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT title, w1, w2, w3, count FROM\n",
        "(\n",
        "  SELECT\n",
        "  title,\n",
        "  ROW_NUMBER() OVER (PARTITION BY title ORDER BY count DESC) AS row,\n",
        "  w1, w2, w3, count\n",
        "  FROM ( %s )\n",
        ")\n",
        "WHERE row = 1\n",
        "ORDER BY title ASC\n",
        "\"\"\" % subquery\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1usOstyw5a5",
        "outputId": "6eadf887-4bd7-4756-e4f6-52cb559d34c9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------+------+-----+\n",
            "|    title|  w1|    w2|    w3|count|\n",
            "+---------+----+------+------+-----+\n",
            "|Chapter 1|that|    he|   was|   16|\n",
            "|Chapter 2|that|    it|   was|   14|\n",
            "|Chapter 3| the|United|States|  396|\n",
            "|  Preface| one|    of|   the|   14|\n",
            "+---------+----+------+------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}